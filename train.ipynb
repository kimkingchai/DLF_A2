{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import albumentations as A\n",
    "from sklearn.model_selection import train_test_split\n",
    "from fastai.vision.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "VAL_RATIO = 0.2\n",
    "IMAGE_SIZE = 224\n",
    "DATASET_ROOT = Path(\"dog-emotions-prediction\")\n",
    "IMAGE_ROOT = DATASET_ROOT / Path(\"images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(x=42):\n",
    "    random.seed(x)\n",
    "    np.random.seed(x)\n",
    "    torch.manual_seed(x)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    if torch.cuda.is_available(): torch.cuda.manual_seed_all(x)\n",
    "\n",
    "set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cusTrainTestSplitter(\n",
    "    test_size=0.2, random_state=None, stratify=False, train_size=None, shuffle=True\n",
    "):\n",
    "    \"Split `items` into random train and test subsets using sklearn train_test_split utility.\"\n",
    "\n",
    "    def _inner(o, **kwargs):\n",
    "        o = list(o)\n",
    "        labels = [i.parent.name for i in o]\n",
    "        train, valid = train_test_split(\n",
    "            range_of(o),\n",
    "            test_size=test_size,\n",
    "            random_state=random_state,\n",
    "            stratify=labels if not stratify else None,\n",
    "            train_size=train_size,\n",
    "            shuffle=shuffle,\n",
    "        )\n",
    "        return L(train), L(valid)\n",
    "\n",
    "    return _inner\n",
    "\n",
    "\n",
    "class AlbumentationsTransform(DisplayedTransform):\n",
    "    split_idx, order = 0, 2\n",
    "\n",
    "    def __init__(self, train_aug):\n",
    "        store_attr()\n",
    "\n",
    "    def encodes(self, img: PILImage):\n",
    "        aug_img = self.train_aug(image=np.array(img))[\"image\"]\n",
    "        return PILImage.create(aug_img)\n",
    "\n",
    "\n",
    "def get_train_aug():\n",
    "    return A.Compose(\n",
    "        [\n",
    "            A.HueSaturationValue(\n",
    "                hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5\n",
    "            ),\n",
    "            A.CoarseDropout(p=0.5),\n",
    "            A.Cutout(p=0.5),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "dblock = DataBlock(\n",
    "    blocks=(ImageBlock, CategoryBlock),\n",
    "    get_items=get_image_files,\n",
    "    splitter=cusTrainTestSplitter(\n",
    "        test_size=VAL_RATIO, random_state=SEED, shuffle=True, stratify=True\n",
    "    ),\n",
    "    get_y=lambda x: x.parent.name,\n",
    "    item_tfms=[AlbumentationsTransform(get_train_aug()), Resize(IMAGE_SIZE), ToTensor],\n",
    "    batch_tfms=[IntToFloatTensor, Normalize.from_stats(*imagenet_stats)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = dblock.dataloaders(IMAGE_ROOT)\n",
    "learn = vision_learner(dls,\"resnet34\",loss_func=CrossEntropyLossFlat(),opt_func=Adam,metrics=F1Score(average='macro'))\n",
    "learn.fine_tune(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
